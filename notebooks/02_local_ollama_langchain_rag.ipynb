{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented LLM with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load llama3.2 model\n",
    "llm = Ollama(model=\"llama3.2\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding model from huggingface\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"nomic-ai/modernbert-embed-base\", trust_remote_code=True, cache_folder='./hf_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup setting\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SimpleDirectoryReader(\n",
    "    input_dir = \"../data\",\n",
    "    required_exts=[\".pdf\"],\n",
    "    recursive=True\n",
    ")\n",
    "docs = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 56/56 [00:00<00:00, 4940.50it/s]\n",
      "Generating embeddings: 100%|██████████| 56/56 [00:08<00:00,  6.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# create index from documents\n",
    "index = VectorStoreIndex.from_documents(docs, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query pattern following\n",
    "# # https://docs.llamaindex.ai/en/stable/module_guides/models/prompts/usage_pattern/\n",
    "\n",
    "query_engine = index.as_query_engine(streaming=False)\n",
    "\n",
    "qa_prompt_tmpl_str = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information, \"\n",
    "    \"answer the query. In case you don't find information in the context,\"\n",
    "    \"answer it anyway with your general knowledge, and don't mention that you\"\n",
    "    \"didn't find information in the context\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"what is an agent, how does it differ from agentic workflow?\"\n",
    "\n",
    "response = query_engine.query(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to the text, an \"agent\" refers to a system where a Large Language Model (LLM) dynamically directs its own processes and tool usage, maintaining control over how it accomplishes tasks. This differs from agentic workflows, which are systems where LLMs and tools are orchestrated through predefined code paths.\n",
       "\n",
       "In other words, agents have a level of autonomy and self-direction, allowing them to make decisions and adapt to their environment in real-time, whereas agentic workflows follow a more rigid and structured approach."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
