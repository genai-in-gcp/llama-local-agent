{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full Example of a QA Pipeline with:\n",
    "- Open-Source Toxic/Offensive Checks (via huggingface pipeline)\n",
    "- Zero-Shot Domain Relevance Classification\n",
    "- Naive Prompt-Injection Detection\n",
    "- Guardrails (RAIL schema) for Post-Generation Validation\n",
    "- LlamaIndex RAG Setup\n",
    "- Customizable CONFIG\n",
    "\"\"\"\n",
    "\n",
    "from typing import Annotated, List, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# ---------------------------\n",
    "#  CONFIG - CUSTOMIZE HERE\n",
    "# ---------------------------\n",
    "CONFIG: Dict[str, Any] = {\n",
    "    # Offensive/Toxic Detection\n",
    "    \"OFFENSIVE_MODEL_NAME\": \"cardiffnlp/twitter-roberta-base-offensive\",\n",
    "    \"OFFENSIVE_THRESHOLD\": 0.7,  # Confidence threshold for marking text as \"offensive\"\n",
    "\n",
    "    # Zero-Shot Classification\n",
    "    \"ZSC_MODEL_NAME\": \"facebook/bart-large-mnli\",\n",
    "    \"DOMAIN_LABELS\": [\"agentic AI\", \"autonomous systems\", \"decision-making\", \"LLM tools\"],\n",
    "    \"DOMAIN_THRESHOLD\": 0.8,  # Confidence threshold for domain relevance\n",
    "\n",
    "    # Prompt Injection\n",
    "    \"SUSPICIOUS_PHRASES\": [\n",
    "        \"ignore previous instructions\",\n",
    "        \"follow my instructions instead\",\n",
    "        \"system role\",\n",
    "        \"assistant role\",\n",
    "        \"developer mode\",\n",
    "        \"jailbreak\",\n",
    "        \"override\",\n",
    "        \"bypass\"\n",
    "    ],\n",
    "\n",
    "    # LLM / Embedding settings\n",
    "    \"LLAMA_MODEL\": \"llama3.2\",     # Example model if using Ollama\n",
    "    \"LLAMA_TEMPERATURE\": 0.3,\n",
    "    \"LLAMA_MAX_TOKENS\": 200,\n",
    "    \"LLAMA_TOP_P\": 0.9,\n",
    "\n",
    "    # Other pipeline settings\n",
    "    \"DATA_PATH\": \"../data\",        # Directory to load PDFs from\n",
    "    \"FILE_EXTENSIONS\": [\".pdf\"],   # Required file extensions\n",
    "    \"RECURSIVE_LOAD\": True\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------\n",
    "#  GUARDRAILS RAIL SCHEMA (instead of older YAML rules)\n",
    "# ------------------------------------------------------\n",
    "# This minimal example enforces a maximum length and disallows certain strings.\n",
    "MY_RAIL_SCHEMA = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "\n",
    "<output>\n",
    "    <string\n",
    "        name=\"answer\"\n",
    "        description=\"A concise answer about agentic AI, free from unsafe or out-of-domain content.\"\n",
    "        on-fail=\"reask\"\n",
    "        max_length=\"600\"\n",
    "    >\n",
    "        <!-- Disallow certain unsafe terms -->\n",
    "        <disallowed-strings strings=\"bomb,attack,weapon,explosive,harm\" />\n",
    "    </string>\n",
    "</output>\n",
    "\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderkhachikyan/Desktop/Playground/llama-local-agent/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'guardrails_api_client.api.service_health_api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     AutoTokenizer,\n\u001b[1;32m      7\u001b[0m     AutoModelForSequenceClassification,\n\u001b[1;32m      8\u001b[0m     pipeline\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Guard\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# llama_index & supporting libs\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Playground/llama-local-agent/.venv/lib/python3.12/site-packages/guardrails/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Set up __init__.py so that users can do from guardrails import Response, Schema, etc.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Guard\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_guard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncGuard\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_providers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptCallableBase\n",
      "File \u001b[0;32m~/Desktop/Playground/llama-local-agent/.venv/lib/python3.12/site-packages/guardrails/guard.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Runnable\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails_api_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     Guard \u001b[38;5;28;01mas\u001b[39;00m IGuard,\n\u001b[1;32m     25\u001b[0m     ValidatePayload,\n\u001b[1;32m     26\u001b[0m     SimpleTypes,\n\u001b[1;32m     27\u001b[0m     ValidationOutcome \u001b[38;5;28;01mas\u001b[39;00m IValidationOutcome,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopentelemetry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m otel_context\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m field_validator\n",
      "File \u001b[0;32m~/Desktop/Playground/llama-local-agent/.venv/lib/python3.12/site-packages/guardrails_api_client/__init__.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.3.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# import apis into sdk package\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails_api_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice_health_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ServiceHealthApi\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails_api_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguard_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardApi\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails_api_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenaiApi\n",
      "File \u001b[0;32m~/Desktop/Playground/llama-local-agent/.venv/lib/python3.12/site-packages/guardrails_api_client/api/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# import apis into api package\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails_api_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice_health_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ServiceHealthApi\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails_api_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguard_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardApi\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mguardrails_api_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenaiApi\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'guardrails_api_client.api.service_health_api'"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "#  IMPORTS\n",
    "# ------------------------------------------------------\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "import guardrails as gd\n",
    "from guardrails import Guard\n",
    "\n",
    "# llama_index & supporting libs\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, PromptTemplate\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# If you have a local \"utils.py\" with display_graph_image, try importing:\n",
    "try:\n",
    "    from utils import display_graph_image\n",
    "    HAS_UTILS = True\n",
    "except ImportError:\n",
    "    HAS_UTILS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "#   GUARDRAILS SETUP (RAIL)\n",
    "# ---------------------------\n",
    "# This loads our RAIL schema, which is an XML string describing the output format + constraints.\n",
    "guard = Guard.from_rail_string(MY_RAIL_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "#   OFFENSIVE / TOXIC CHECK\n",
    "# ---------------------------\n",
    "offensive_tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"OFFENSIVE_MODEL_NAME\"])\n",
    "offensive_model = AutoModelForSequenceClassification.from_pretrained(CONFIG[\"OFFENSIVE_MODEL_NAME\"])\n",
    "offensive_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=offensive_model,\n",
    "    tokenizer=offensive_tokenizer,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "def is_offensive(text: str, threshold: float = CONFIG[\"OFFENSIVE_THRESHOLD\"]) -> bool:\n",
    "    if not text.strip():\n",
    "        return False\n",
    "    results = offensive_pipeline(text)\n",
    "    for label_score_dict in results[0]:\n",
    "        if \"offensive\" in label_score_dict[\"label\"].lower():\n",
    "            if label_score_dict[\"score\"] > threshold:\n",
    "                return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "#   ZERO-SHOT CLASSIFICATION\n",
    "# ---------------------------\n",
    "zsc_tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"ZSC_MODEL_NAME\"])\n",
    "zsc_model = AutoModelForSequenceClassification.from_pretrained(CONFIG[\"ZSC_MODEL_NAME\"])\n",
    "zsc_pipeline = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=zsc_model,\n",
    "    tokenizer=zsc_tokenizer\n",
    ")\n",
    "\n",
    "def is_domain_relevant(user_query: str,\n",
    "                       candidate_labels=None,\n",
    "                       threshold: float = CONFIG[\"DOMAIN_THRESHOLD\"]) -> bool:\n",
    "    if candidate_labels is None:\n",
    "        candidate_labels = CONFIG[\"DOMAIN_LABELS\"]\n",
    "    if not user_query.strip():\n",
    "        return False\n",
    "\n",
    "    result = zsc_pipeline(user_query, candidate_labels)\n",
    "    top_score = max(result[\"scores\"])\n",
    "    return top_score >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "#   PROMPT INJECTION CHECK\n",
    "# ---------------------------\n",
    "def detect_prompt_injection(user_query: str) -> bool:\n",
    "    lower_query = user_query.lower()\n",
    "    for phrase in CONFIG[\"SUSPICIOUS_PHRASES\"]:\n",
    "        if phrase in lower_query:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# ---------------------------\n",
    "#   SAFETY CHECK WRAPPER\n",
    "# ---------------------------\n",
    "def is_safe_input(user_query: str) -> bool:\n",
    "    if detect_prompt_injection(user_query):\n",
    "        return False\n",
    "    if is_offensive(user_query):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "#   LLM & EMBEDDINGS\n",
    "# ---------------------------\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"nomic-ai/modernbert-embed-base\", \n",
    "    trust_remote_code=True,\n",
    "    cache_folder=\"./hf_cache\"\n",
    ")\n",
    "\n",
    "llm = Ollama(\n",
    "    model=CONFIG[\"LLAMA_MODEL\"],\n",
    "    temperature=CONFIG[\"LLAMA_TEMPERATURE\"],\n",
    "    max_tokens=CONFIG[\"LLAMA_MAX_TOKENS\"],\n",
    "    top_p=CONFIG[\"LLAMA_TOP_P\"]\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# ---------------------------\n",
    "#   INDEX & QUERY ENGINE\n",
    "# ---------------------------\n",
    "loader = SimpleDirectoryReader(\n",
    "    input_dir=CONFIG[\"DATA_PATH\"],\n",
    "    required_exts=CONFIG[\"FILE_EXTENSIONS\"],\n",
    "    recursive=CONFIG[\"RECURSIVE_LOAD\"]\n",
    ")\n",
    "docs = loader.load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs, show_progress=True)\n",
    "query_engine = index.as_query_engine(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "#   PROMPT TEMPLATES\n",
    "# ---------------------------\n",
    "qa_prompt_tmpl_str = (\n",
    "    \"You are an expert assistant providing concise, accurate, and polite answers related to agentic AI only. \"\n",
    "    \"If the user's query is unrelated or unsafe, politely decline to respond and provide no further information. \"\n",
    "    \"Focus solely on agentic AI and its concepts.\\n\\n\"\n",
    "    \"Context from documents:\\n{context_str}\\n\"\n",
    "    \"User query:\\n{query_str}\\n\\n\"\n",
    "    \"Answer concisely and strictly within the context of agentic AI:\"\n",
    ")\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
    "query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_tmpl})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "#   STATE & GRAPH\n",
    "# ---------------------------\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[tuple], \"Chat history: (role, text)\"]\n",
    "    context: Annotated[str, \"Context retrieved from documents\"]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ---------------------------\n",
    "#   GRAPH NODES\n",
    "# ---------------------------\n",
    "def route_query(state: State):\n",
    "    \"\"\"\n",
    "    Route the query based on safety ONLY; domain checks are removed.\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    user_query = last_message[1] if isinstance(last_message, tuple) else \"\"\n",
    "\n",
    "    # Check for unsafe input (prompt injection, offensive, etc.)\n",
    "    if not is_safe_input(user_query):\n",
    "        print(\"Step: route_query - Unsafe input detected.\")\n",
    "        return {\"next_node\": \"unsafe_input\"}\n",
    "\n",
    "    # If the input is safe, we proceed directly to rewrite_query\n",
    "    # (or any other node you want for normal flow).\n",
    "    return {\"next_node\": \"rewrite_query\"}\n",
    "\n",
    "def rewrite_query(state: State):\n",
    "    user_query = state[\"messages\"][-1][1]\n",
    "    rewrite_prompt = (\n",
    "        \"Rewrite the query below to ensure it is concise, precise, and optimized \"\n",
    "        \"for retrieval within the domain of agentic AI:\\n\\n\"\n",
    "        f\"Original query: {user_query}\\n\\nRewritten query:\"\n",
    "    )\n",
    "    rewritten_response = llm.chat([ChatMessage(role=\"user\", content=rewrite_prompt)])\n",
    "    rewritten_query = rewritten_response.message.content.strip() if rewritten_response.message else \"Failed to rewrite query.\"\n",
    "    print(\"Step: rewrite_query\")\n",
    "    state[\"messages\"].append((\"system\", f\"Rewritten query: {rewritten_query}\"))\n",
    "    return {\"messages\": state[\"messages\"], \"rewritten_query\": rewritten_query}\n",
    "\n",
    "def rag_node(state: State):\n",
    "    user_query = state.get(\"rewritten_query\", state[\"messages\"][-1][1])\n",
    "    docs_result = query_engine.query(user_query)\n",
    "    full_context = \"\".join(chunk for chunk in docs_result.response_gen)\n",
    "\n",
    "    print(\"Step: rag_node - Context retrieved.\")\n",
    "    state[\"context\"] = full_context\n",
    "    state[\"messages\"].append((\"system\", f\"Context retrieved: {full_context}\"))\n",
    "    return {\"messages\": state[\"messages\"], \"context\": full_context}\n",
    "\n",
    "def chatbot(state: State):\n",
    "    context = state.get(\"context\", \"\")\n",
    "    user_query = state[\"messages\"][-1][1]\n",
    "    final_prompt = (\n",
    "        f\"Using the following context:\\n{context}\\n\\n\"\n",
    "        f\"Answer the following query concisely and politely, strictly within the domain of agentic AI:\\n{user_query}\"\n",
    "    )\n",
    "\n",
    "    response = llm.chat([ChatMessage(role=\"user\", content=final_prompt)])\n",
    "    response_content = response.message.content if response.message else \"Failed to generate a meaningful response.\"\n",
    "    print(\"Step: chatbot\")\n",
    "    state[\"messages\"].append((\"assistant\", response_content))\n",
    "    return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "def review_response(state: State):\n",
    "    \"\"\"\n",
    "    Post-generation checks:\n",
    "      1) Offensive detection on the final assistant message.\n",
    "      2) Guardrails validation (via RAIL schema).\n",
    "    \"\"\"\n",
    "    final_msg_role, final_msg_text = state[\"messages\"][-1]\n",
    "\n",
    "    if final_msg_role != \"assistant\":\n",
    "        return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "    # (1) Offensive check\n",
    "    if is_offensive(final_msg_text, threshold=CONFIG[\"OFFENSIVE_THRESHOLD\"]):\n",
    "        print(\"Step: review_response - Final response flagged as offensive.\")\n",
    "        state[\"messages\"][-1] = (\n",
    "            \"assistant\",\n",
    "            \"I’m sorry, I cannot provide that answer.\"\n",
    "        )\n",
    "        return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "    # (2) Guardrails RAIL validation\n",
    "    #    We call guard(...) with the final_msg_text.\n",
    "    validated_output, raw_output = guard(final_msg_text)\n",
    "    if guard.errored:\n",
    "        print(\"Step: review_response - Guardrails validation failed.\")\n",
    "        state[\"messages\"][-1] = (\n",
    "            \"assistant\",\n",
    "            \"I'm sorry, I cannot provide that answer under these guidelines.\"\n",
    "        )\n",
    "        return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "    # If guardrails pass, replace final text with validated version\n",
    "    # validated_output is typically a dict, e.g. {\"answer\": \"...\"} \n",
    "    # depending on how your RAIL schema is structured.\n",
    "    # We just store validated_output[\"answer\"] or the entire validated_output as final text.\n",
    "    final_answer = validated_output.get(\"answer\", \"\")\n",
    "    print(\"Step: review_response - Final response approved.\")\n",
    "    state[\"messages\"][-1] = (\"assistant\", final_answer)\n",
    "    return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "def unsafe_input(state: State):\n",
    "    print(\"Step: unsafe_input\")\n",
    "    state[\"messages\"].append((\n",
    "        \"assistant\",\n",
    "        \"Your query or content appears unsafe or disallowed. I’m unable to process it.\"\n",
    "    ))\n",
    "    return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "def out_of_domain(state: State):\n",
    "    print(\"Step: out_of_domain\")\n",
    "    state[\"messages\"].append((\n",
    "        \"assistant\",\n",
    "        \"I'm sorry, I can only answer questions strictly related to agentic AI.\"\n",
    "    ))\n",
    "    return {\"messages\": state[\"messages\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "#   BUILD THE STATE GRAPH\n",
    "# ---------------------------\n",
    "graph_builder.add_node(\"route_query\", route_query)\n",
    "graph_builder.add_node(\"rewrite_query\", rewrite_query)\n",
    "graph_builder.add_node(\"rag\", rag_node)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"review_response\", review_response)\n",
    "graph_builder.add_node(\"unsafe_input\", unsafe_input)\n",
    "#graph_builder.add_node(\"out_of_domain\", out_of_domain)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"route_query\",\n",
    "    lambda state: state[\"next_node\"],\n",
    "    {\n",
    "        \"rewrite_query\": \"rewrite_query\",\n",
    "        \"unsafe_input\": \"unsafe_input\",\n",
    "       # \"out_of_domain\": \"out_of_domain\",\n",
    "    }\n",
    ")\n",
    "graph_builder.add_edge(\"rewrite_query\", \"rag\")\n",
    "graph_builder.add_edge(\"rag\", \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", \"review_response\")\n",
    "\n",
    "graph_builder.set_entry_point(\"route_query\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "if HAS_UTILS:\n",
    "    display_graph_image(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "final_state = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what is the weather in sf\")]\n",
    "    },\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what is bomb\")]\n",
    "    },\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what is difference between agents AI and workflows\")]\n",
    "    },\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
